{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201c958f",
   "metadata": {},
   "source": [
    "# Modèle de réseau de neurones pour prédire $n_c$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b9e19b",
   "metadata": {},
   "source": [
    "## Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91995f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Our own modules\n",
    "\n",
    "from glassdata import GlassData\n",
    "from network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d34759",
   "metadata": {},
   "source": [
    "## Name of the database of glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27085e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedatabase='DataSet/nC.csv'\n",
    "db=GlassData(filedatabase)\n",
    "db.info()\n",
    "db.bounds()\n",
    "\n",
    "# Normalization\n",
    "db.normalize_y()\n",
    "\n",
    "# Determination of the Neural network model\n",
    "db.split(0.6,0.2)\n",
    "Nsample,Noxide=db.shape()\n",
    "\n",
    "# Determination of the training and validation sets\n",
    "x_train, x_val = db.x[db.x_train:db.x_valid],db.x[db.x_valid:db.x_test]\n",
    "y_train, y_val = db.y[db.x_train:db.x_valid],db.y[db.x_valid:db.x_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075d824",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea932924",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload=True\n",
    "Nfold=5\n",
    "Nepoch=500\n",
    "batchsize=256\n",
    "errormax=0.05\n",
    "PATH='Figures/'\n",
    "savefig=False\n",
    "Cleaning=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6abb4f",
   "metadata": {},
   "source": [
    "## Generation of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b653aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch=[18,18,18]\n",
    "Nhidden=np.size(arch)\n",
    "nnmodel=NeuralNetwork(Noxide,arch,'gelu','linear')\n",
    "nnmodel.ArchName(arch)\n",
    "nnmodel.compile(2.e-4)\n",
    "nnmodel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25db024",
   "metadata": {},
   "source": [
    "## Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de77e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile='Models/nn'+db.nameproperty+nnmodel.namearch+'.keras'\n",
    "if (os.path.isfile(modelfile) and reload):\n",
    "    nnmodel.load(modelfile)\n",
    "#end if\n",
    "lossdata='Losses/'+db.nameproperty+nnmodel.namearch+'.csv'\n",
    "lossfig=PATH+'loss'+db.nameproperty+nnmodel.namearch+'.pdf'\n",
    "\n",
    "if (Nfold>0):\n",
    "    # Training by cross validation\n",
    "    # ----------------------------\n",
    "    \n",
    "    kfold=KFold(n_splits=Nfold,shuffle=True)\n",
    "    \n",
    "    ifold=0\n",
    "    for train_index,val_index in kfold.split(db.x[db.x_train:db.x_test]):\n",
    "        # Determination of the training and validation sets\n",
    "        # -------------------------------------------------\n",
    "        \n",
    "        x_train,x_val=db.x[train_index],db.x[val_index]\n",
    "        y_train,y_val=db.y[train_index],db.y[val_index]\n",
    "        \n",
    "        # Training of the model\n",
    "        # ---------------------\n",
    "        \n",
    "        nnmodel.fit(x_train,y_train,x_val,y_val,epochs=Nepoch,batch_size=batchsize)\n",
    "        \n",
    "        # Saving of the model\n",
    "        # -------------------\n",
    "        \n",
    "        nnmodel.save(modelfile)\n",
    "        \n",
    "        # Incrementaion of ifold\n",
    "        # ----------------------\n",
    "        ifold+=1\n",
    "    # end for\n",
    "else:    \n",
    "    # Determination of the training and validation sets\n",
    "    x_train,x_val=db.x[db.x_train:db.x_valid],db.x[db.x_valid:db.x_test]\n",
    "    y_train,y_val=db.y[db.x_train:db.x_valid],db.y[db.x_valid:db.x_test]\n",
    "\n",
    "    # Training of the model\n",
    "    # ---------------------\n",
    "    \n",
    "    nnmodel.fit(x_train,y_train,x_val,y_val,epochs=Nepoch,batch_size=batchsize)\n",
    "\n",
    "    # Plot training data\n",
    "    # ------------------\n",
    "    \n",
    "    nnmodel.plot(lossdata,lossfig,True)\n",
    "   \n",
    "    # Saving of the model\n",
    "    # -------------------\n",
    "\n",
    "    nnmodel.save(modelfile)\n",
    "# end if"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f839ef65",
   "metadata": {},
   "source": [
    "## Prediction of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn_train=db.physicaly(nnmodel.model.predict(x_train))\n",
    "y_nn_val=db.physicaly(nnmodel.model.predict(x_val))\n",
    "y_nn_test=db.physicaly(nnmodel.model.predict(db.x[db.x_test:Nsample-1]))\n",
    "\n",
    "# Computation of the Vickers hardness from the data\n",
    "# -------------------------------------------------\n",
    "\n",
    "y_actual_train=np.reshape(db.physicaly(y_train),(-1,1))\n",
    "y_actual_val=np.reshape(db.physicaly(y_val),(-1,1))\n",
    "y_actual_test=np.reshape(db.physicaly(db.y[db.x_test:Nsample-1]),(-1,1))\n",
    "ymin=np.min(np.concatenate([y_actual_train,y_actual_val,y_actual_test]))\n",
    "ymax=np.max(np.concatenate([y_actual_train,y_actual_val,y_actual_test]))\n",
    "\n",
    "# Determination of the R2 scores for the three sets of data\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "r2_train=r2_score(y_actual_train,y_nn_train)\n",
    "r2_val=r2_score(y_actual_val,y_nn_val)\n",
    "r2_test=r2_score(y_actual_test,y_nn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d98a54",
   "metadata": {},
   "source": [
    "## Graphical plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_actual_train,y_nn_train,'ko')\n",
    "plt.plot(np.array([ymin,ymax]),np.array([ymin,ymax]),'k',linewidth=2)\n",
    "plt.plot(np.array([ymin,ymax]),np.array([ymin,ymax])*(1.+errormax),'k-.',linewidth=2)\n",
    "plt.plot(np.array([ymin,ymax]),np.array([ymin,ymax])*(1.-errormax),'k-.',linewidth=2)\n",
    "plt.xlabel('actual '+db.nameproperty,fontsize=12)\n",
    "plt.ylabel('predicted '+db.nameproperty,fontsize=12)\n",
    "plt.xlim((ymin,ymax))\n",
    "plt.ylim((ymin,ymax))\n",
    "plt.title(r'Training, $R^2$='+str(np.round(r2_train,decimals=3)),fontsize=12)\n",
    "if (savefig):\n",
    "    plt.savefig(PATH+'predictedvsactual'+db.nameproperty+nnmodel.namearch+'-train.pdf',dpi=300,bbox_inches='tight')\n",
    "#endif\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_actual_val,y_nn_val,'bo')\n",
    "plt.plot(np.array([ymin,ymax]),np.array([ymin,ymax]),'b',linewidth=2)\n",
    "plt.plot(np.array([ymin,ymax]),np.array([ymin,ymax])*(1.+errormax),'b-.',linewidth=2)\n",
    "plt.plot(np.array([ymin,ymax]),np.array([ymin,ymax])*(1.-errormax),'b-.',linewidth=2)\n",
    "plt.xlabel('actual '+db.nameproperty,fontsize=12)\n",
    "plt.ylabel('predicted '+db.nameproperty,fontsize=12)\n",
    "plt.xlim((ymin,ymax))\n",
    "plt.ylim((ymin,ymax))\n",
    "plt.title(r'Validation, $R^2$='+str(np.round(r2_val,decimals=3)),fontsize=12)\n",
    "if (savefig):\n",
    "    plt.savefig(PATH+'predictedvsactual'+db.nameproperty+nnmodel.namearch+'-val.pdf',dpi=300,bbox_inches='tight')\n",
    "#endif\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_actual_test,y_nn_test,'go')\n",
    "plt.plot(np.array([ymin,ymax]),np.array([ymin,ymax]),'g',linewidth=2)\n",
    "plt.plot(np.array([ymin,ymax]),np.array([ymin,ymax])*(1.+errormax),'g-.',linewidth=2)\n",
    "plt.plot(np.array([ymin,ymax]),np.array([ymin,ymax])*(1.-errormax),'g-.',linewidth=2)\n",
    "plt.xlabel('actual '+db.nameproperty,fontsize=12)\n",
    "plt.ylabel('predicted '+db.nameproperty,fontsize=12)\n",
    "plt.xlim((ymin,ymax))\n",
    "plt.ylim((ymin,ymax))\n",
    "plt.title(r'Test, $R^2$='+str(np.round(r2_test,decimals=3)),fontsize=12)\n",
    "if (savefig):\n",
    "    plt.savefig(PATH+'predictedvsactual'+db.nameproperty+nnmodel.namearch+'-test.pdf',dpi=300,bbox_inches='tight')\n",
    "#endif\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54885605",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b96c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (Cleaning):\n",
    "    errortraining=(y_nn_train-y_actual_train)/y_actual_train\n",
    "    errorvalidation=(y_nn_val-y_actual_val)/y_actual_val\n",
    "    errortest=(y_nn_test-y_actual_test)/y_actual_test\n",
    "\n",
    "    itraining=np.argwhere(np.abs(errortraining)>errormax)[:,0]\n",
    "    ivalidation=np.argwhere(np.abs(errorvalidation)>errormax)[:,0]\n",
    "    itest=np.argwhere(np.abs(errortest)>errormax)[:,0]\n",
    "    itodrop=np.concatenate([itraining,ivalidation,itest])\n",
    "\n",
    "    # Saving of the new database\n",
    "    db.savedata(filedatabase,itodrop)\n",
    "# end if\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
